{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b716df6-4e20-447c-b6e0-d07bfd4d3d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import simulate_CPU_devices\n",
    "\n",
    "simulate_CPU_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "48a31b03-43d8-4ad4-9fef-4409926db275",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[CpuDevice(id=0),\n",
       " CpuDevice(id=1),\n",
       " CpuDevice(id=2),\n",
       " CpuDevice(id=3),\n",
       " CpuDevice(id=4),\n",
       " CpuDevice(id=5),\n",
       " CpuDevice(id=6),\n",
       " CpuDevice(id=7)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a0f977e-8a55-4ec1-b7a6-fef2333d3c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "from pprint import pprint\n",
    "from typing import Any, Callable, Dict, Sequence, Tuple\n",
    "\n",
    "import flax.linen as nn\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import optax\n",
    "from absl import logging\n",
    "from jax import lax\n",
    "from jax.experimental.shard_map import shard_map\n",
    "from jax.sharding import Mesh\n",
    "from jax.sharding import PartitionSpec as P\n",
    "from ml_collections import ConfigDict\n",
    "\n",
    "PyTree = Any\n",
    "Metrics = Dict[str, Tuple[jax.Array, ...]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ab920a1-393f-4b19-91eb-0ebe591b3dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from single_gpu import Batch, TrainState, accumulate_gradients, print_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b30969ad-9479-4845-b149-0df96330de13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fold_rng_over_axis(rng: jax.random.PRNGKey, axis_name: str) -> jax.random.PRNGKey:\n",
    "    \"\"\"Folds the random number generator over the given axis.\n",
    "\n",
    "    This is useful for generating a different random number for each device\n",
    "    across a certain axis (e.g. the model axis).\n",
    "\n",
    "    Args:\n",
    "        rng: The random number generator.\n",
    "        axis_name: The axis name to fold the random number generator over.\n",
    "\n",
    "    Returns:\n",
    "        A new random number generator, different for each device index along the axis.\n",
    "    \"\"\"\n",
    "    axis_index = jax.lax.axis_index(axis_name)\n",
    "    return jax.random.fold_in(rng, axis_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cbfe0d17-78c0-42a8-9c69-d5355c3a4d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DPClassifier(nn.Module):\n",
    "    config: ConfigDict\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x: jax.Array, train: bool) -> jax.Array:\n",
    "        x = nn.Dense(\n",
    "            features=self.config.hidden_size,\n",
    "            dtype=self.config.dtype,\n",
    "            name=\"input_dense\",\n",
    "        )(x)\n",
    "        x = nn.silu(x)\n",
    "        x = nn.Dropout(rate=self.config.dropout_rate, deterministic=not train)(x)\n",
    "        x = nn.Dense(\n",
    "            features=self.config.num_classes,\n",
    "            dtype=self.config.dtype,\n",
    "            name=\"output_dense\",\n",
    "        )(x)\n",
    "        x = x.astype(jnp.float32)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3fa5928e-5d0c-41c2-abe4-dac87296ba24",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_config = ConfigDict(\n",
    "    dict(\n",
    "        batch_size=128,\n",
    "        num_classes=10,\n",
    "        input_size=784,\n",
    "    )\n",
    ")\n",
    "model_config = ConfigDict(\n",
    "    dict(\n",
    "        hidden_size=512,\n",
    "        dropout_rate=0.1,\n",
    "        dtype=jnp.bfloat16,\n",
    "        num_classes=data_config.num_classes,\n",
    "        data_axis_name=\"data\",\n",
    "    )\n",
    ")\n",
    "optimizer_config = ConfigDict(\n",
    "    dict(\n",
    "        learning_rate=1e-3,\n",
    "        num_minibatches=4,\n",
    "    )\n",
    ")\n",
    "config = ConfigDict(\n",
    "    dict(\n",
    "        model=model_config,\n",
    "        optimizer=optimizer_config,\n",
    "        data=data_config,\n",
    "        data_axis_name=model_config.data_axis_name,\n",
    "        seed=42,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41df60d3-d1a0-4824-b1b8-26d22d67664a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dp = DPClassifier(config=config.model)\n",
    "optimizer = optax.adamw(\n",
    "    learning_rate=config.optimizer.learning_rate,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "958eb7cb-431e-4729-ad8e-828a6af95651",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = jax.random.PRNGKey(config.seed)\n",
    "model_init_rng, data_inputs_rng, data_labels_rng = jax.random.split(rng, 3)\n",
    "batch = Batch(\n",
    "    inputs=jax.random.normal(data_inputs_rng, (config.data.batch_size, config.data.input_size)),\n",
    "    labels=jax.random.randint(\n",
    "        data_labels_rng, (config.data.batch_size,), 0, config.data.num_classes\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1cb55a1-f7f8-4cac-b266-865f42e0ae70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0 42] [3134548294 3733159049] [3746501087  894150801] [ 801545058 2363201431]\n"
     ]
    }
   ],
   "source": [
    "print(rng, model_init_rng, data_inputs_rng, data_labels_rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf477876-f822-4c55-8f53-d455fe7e0e0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.9723122  -1.2452544   0.17470965 ...  0.08267392 -0.89882183\n",
      "   0.0232077 ]\n",
      " [ 0.8691865   0.64485383 -1.8292103  ... -1.555047    0.82450116\n",
      "   0.2290802 ]\n",
      " [ 0.7618328  -0.07111705 -0.4348067  ...  0.7814184  -0.46264035\n",
      "   0.3288694 ]\n",
      " ...\n",
      " [ 1.4671646   0.48726186 -0.51675266 ... -0.03286455 -0.5917859\n",
      "  -0.7451234 ]\n",
      " [ 1.2910836  -0.43864703 -0.50237346 ...  1.1371423   0.07289556\n",
      "  -0.24300338]\n",
      " [ 1.2610282   0.6610234  -0.530804   ...  0.32887977 -0.62506366\n",
      "  -0.02475406]]\n"
     ]
    }
   ],
   "source": [
    "print(batch.inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa923aea-5111-48df-b689-4f8039fc4dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_dp(rng: jax.random.PRNGKey, x: jax.Array, model: nn.Module) -> TrainState:\n",
    "    init_rng, rng = jax.random.split(rng)\n",
    "    variables = model.init({\"params\": init_rng}, x, train=False)\n",
    "    params = variables.pop(\"params\")\n",
    "    state = TrainState.create(\n",
    "        apply_fn=model.apply,\n",
    "        params=params,\n",
    "        tx=optimizer,\n",
    "        rng=rng,\n",
    "    )\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b6b0c5d8-a098-4429-a251-f33ced7ae516",
   "metadata": {},
   "outputs": [],
   "source": [
    "device_array = np.array(jax.devices())\n",
    "mesh = Mesh(device_array, (config.data_axis_name,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c4434878-ff04-4180-a210-6d9d2dd07566",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_dp_fn = jax.jit(\n",
    "    shard_map(\n",
    "        functools.partial(init_dp, model=model_dp),\n",
    "        mesh,\n",
    "        in_specs=(P(), P(config.data_axis_name)),\n",
    "        out_specs=P(),\n",
    "        check_rep=False,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa5986a7-e6bd-43b4-ab9c-f80ac4f7171e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DP Parameters\n",
      "{'input_dense': {'bias': ((512,),\n",
      "                          NamedSharding(mesh=Mesh('data': 8), spec=PartitionSpec(), memory_kind=unpinned_host)),\n",
      "                 'kernel': ((784, 512),\n",
      "                            NamedSharding(mesh=Mesh('data': 8), spec=PartitionSpec(), memory_kind=unpinned_host))},\n",
      " 'output_dense': {'bias': ((10,),\n",
      "                           NamedSharding(mesh=Mesh('data': 8), spec=PartitionSpec(), memory_kind=unpinned_host)),\n",
      "                  'kernel': ((512, 10),\n",
      "                             NamedSharding(mesh=Mesh('data': 8), spec=PartitionSpec(), memory_kind=unpinned_host))}}\n"
     ]
    }
   ],
   "source": [
    "state_dp = init_dp_fn(model_init_rng, batch.inputs)\n",
    "print(\"DP Parameters\")\n",
    "pprint(jax.tree.map(lambda x: (x.shape, x.sharding), state_dp.params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2ca7dbaa-c19c-474b-8e0b-8fddfdbc901c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(\n",
    "    params: PyTree, apply_fn: Any, batch: Batch, rng: jax.Array\n",
    ") -> Tuple[jax.Array, Dict[str, Any]]:\n",
    "    # Since dropout masks vary across the batch dimension, we want each device to generate a\n",
    "    # different mask. We can achieve this by folding the rng over the data axis, so that each\n",
    "    # device gets a different rng and thus mask.\n",
    "    dropout_rng = fold_rng_over_axis(rng, config.data_axis_name)\n",
    "    # Remaining computation is the same as before for single device.\n",
    "    logits = apply_fn({\"params\": params}, batch.inputs, train=True, rngs={\"dropout\": dropout_rng})\n",
    "    loss = optax.softmax_cross_entropy_with_integer_labels(logits, batch.labels)\n",
    "    correct_pred = jnp.equal(jnp.argmax(logits, axis=-1), batch.labels)\n",
    "    batch_size = batch.inputs.shape[0]\n",
    "    step_metrics = {\"loss\": (loss.sum(), batch_size), \"accuracy\": (correct_pred.sum(), batch_size)}\n",
    "    loss = loss.mean()\n",
    "    return loss, step_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ca86a5f0-bc10-4bfc-bcdd-6c99fee817c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step_dp(\n",
    "    state: TrainState,\n",
    "    metrics: Metrics | None,\n",
    "    batch: Batch,\n",
    ") -> Tuple[TrainState, Metrics]:\n",
    "    rng, step_rng = jax.random.split(state.rng)\n",
    "    grads, step_metrics = accumulate_gradients(\n",
    "        state,\n",
    "        batch,\n",
    "        step_rng,\n",
    "        config.optimizer.num_minibatches,\n",
    "        loss_fn=loss_fn,\n",
    "    )\n",
    "    print(grads)\n",
    "    # jax.debug.visualize_array_sharding(grads['output_dense']['kernel'])\n",
    "    # Update parameters. We need to sync the gradients across devices before updating.\n",
    "    with jax.named_scope(\"sync_gradients\"):\n",
    "        grads = jax.tree.map(lambda g: jax.lax.pmean(g, axis_name=config.data_axis_name), grads)\n",
    "    new_state = state.apply_gradients(grads=grads, rng=rng)\n",
    "    # Sum metrics across replicas. Alternatively, we could keep the metrics separate\n",
    "    # and only synchronize them before logging. For simplicity, we sum them here.\n",
    "    with jax.named_scope(\"sync_metrics\"):\n",
    "        step_metrics = jax.tree_map(\n",
    "            lambda x: jax.lax.psum(x, axis_name=config.data_axis_name), step_metrics\n",
    "        )\n",
    "    if metrics is None:\n",
    "        metrics = step_metrics\n",
    "    else:\n",
    "        metrics = jax.tree_map(jnp.add, metrics, step_metrics)\n",
    "    return new_state, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0e38eb98-5ece-43c0-9cb6-61dec3d42a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_step_dp_fn = jax.jit(\n",
    "    shard_map(\n",
    "        train_step_dp,\n",
    "        mesh,\n",
    "        in_specs=(P(), P(), P(config.data_axis_name)),\n",
    "        out_specs=(P(), P()),\n",
    "        check_rep=False,\n",
    "    ),\n",
    "    donate_argnames=(\"state\", \"metrics\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d1f7a31c-f3bf-469a-bb7d-48216cdc8fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, metric_shapes = jax.eval_shape(\n",
    "    train_step_dp_fn,\n",
    "    state_dp,\n",
    "    None,\n",
    "    batch,\n",
    ")\n",
    "metrics_dp = jax.tree.map(lambda x: jnp.zeros(x.shape, dtype=x.dtype), metric_shapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "bc0def39-051d-41eb-84c2-4cfc26cee28c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_dense': {'bias': Traced<ShapedArray(float32[512])>with<DynamicJaxprTrace>, 'kernel': Traced<ShapedArray(float32[784,512])>with<DynamicJaxprTrace>}, 'output_dense': {'bias': Traced<ShapedArray(float32[10])>with<DynamicJaxprTrace>, 'kernel': Traced<ShapedArray(float32[512,10])>with<DynamicJaxprTrace>}}\n"
     ]
    },
    {
     "ename": "XlaRuntimeError",
     "evalue": "INTERNAL: Error calling inspect_sharding: Traceback (most recent call last):\n  File \"C:\\Users\\leyu0002\\Anaconda3\\envs\\JAX_FLAX\\lib\\runpy.py\", line 196, in _run_module_as_main\n  File \"C:\\Users\\leyu0002\\Anaconda3\\envs\\JAX_FLAX\\lib\\runpy.py\", line 86, in _run_code\n  File \"C:\\Users\\leyu0002\\Anaconda3\\envs\\JAX_FLAX\\lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n  File \"C:\\Users\\leyu0002\\Anaconda3\\envs\\JAX_FLAX\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n  File \"C:\\Users\\leyu0002\\Anaconda3\\envs\\JAX_FLAX\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n  File \"C:\\Users\\leyu0002\\Anaconda3\\envs\\JAX_FLAX\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n  File \"C:\\Users\\leyu0002\\Anaconda3\\envs\\JAX_FLAX\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n  File \"C:\\Users\\leyu0002\\Anaconda3\\envs\\JAX_FLAX\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n  File \"C:\\Users\\leyu0002\\Anaconda3\\envs\\JAX_FLAX\\lib\\asyncio\\events.py\", line 80, in _run\n  File \"C:\\Users\\leyu0002\\Anaconda3\\envs\\JAX_FLAX\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n  File \"C:\\Users\\leyu0002\\Anaconda3\\envs\\JAX_FLAX\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n  File \"C:\\Users\\leyu0002\\Anaconda3\\envs\\JAX_FLAX\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n  File \"C:\\Users\\leyu0002\\Anaconda3\\envs\\JAX_FLAX\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n  File \"C:\\Users\\leyu0002\\Anaconda3\\envs\\JAX_FLAX\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n  File \"C:\\Users\\leyu0002\\Anaconda3\\envs\\JAX_FLAX\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n  File \"C:\\Users\\leyu0002\\Anaconda3\\envs\\JAX_FLAX\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n  File \"C:\\Users\\leyu0002\\Anaconda3\\envs\\JAX_FLAX\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n  File \"C:\\Users\\leyu0002\\Anaconda3\\envs\\JAX_FLAX\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n  File \"C:\\Users\\leyu0002\\Anaconda3\\envs\\JAX_FLAX\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n  File \"C:\\Users\\leyu0002\\Anaconda3\\envs\\JAX_FLAX\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n  File \"C:\\Users\\leyu0002\\Anaconda3\\envs\\JAX_FLAX\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n  File \"C:\\Users\\leyu0002\\Anaconda3\\envs\\JAX_FLAX\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n  File \"C:\\Users\\leyu0002\\AppData\\Local\\Temp\\ipykernel_27612\\784880305.py\", line 2, in <module>\n  File \"C:\\Users\\leyu0002\\Anaconda3\\envs\\JAX_FLAX\\lib\\site-packages\\jax\\_src\\traceback_util.py\", line 180, in reraise_with_filtered_traceback\n  File \"C:\\Users\\leyu0002\\Anaconda3\\envs\\JAX_FLAX\\lib\\site-packages\\jax\\_src\\pjit.py\", line 337, in cache_miss\n  File \"C:\\Users\\leyu0002\\Anaconda3\\envs\\JAX_FLAX\\lib\\site-packages\\jax\\_src\\pjit.py\", line 195, in _python_pjit_helper\n  File \"C:\\Users\\leyu0002\\Anaconda3\\envs\\JAX_FLAX\\lib\\site-packages\\jax\\_src\\pjit.py\", line 1672, in _pjit_call_impl_python\n  File \"C:\\Users\\leyu0002\\Anaconda3\\envs\\JAX_FLAX\\lib\\site-packages\\jax\\_src\\interpreters\\pxla.py\", line 2415, in compile\n  File \"C:\\Users\\leyu0002\\Anaconda3\\envs\\JAX_FLAX\\lib\\site-packages\\jax\\_src\\interpreters\\pxla.py\", line 2923, in from_hlo\n  File \"C:\\Users\\leyu0002\\Anaconda3\\envs\\JAX_FLAX\\lib\\site-packages\\jax\\_src\\interpreters\\pxla.py\", line 2729, in _cached_compilation\n  File \"C:\\Users\\leyu0002\\Anaconda3\\envs\\JAX_FLAX\\lib\\site-packages\\jax\\_src\\compiler.py\", line 452, in compile_or_get_cached\n  File \"C:\\Users\\leyu0002\\Anaconda3\\envs\\JAX_FLAX\\lib\\site-packages\\jax\\_src\\compiler.py\", line 653, in _compile_and_write_cache\n  File \"C:\\Users\\leyu0002\\Anaconda3\\envs\\JAX_FLAX\\lib\\site-packages\\jax\\_src\\profiler.py\", line 333, in wrapper\n  File \"C:\\Users\\leyu0002\\Anaconda3\\envs\\JAX_FLAX\\lib\\site-packages\\jax\\_src\\compiler.py\", line 303, in backend_compile\n  File \"C:\\Users\\leyu0002\\Anaconda3\\envs\\JAX_FLAX\\lib\\site-packages\\jax\\_src\\debugging.py\", line 403, in _hlo_sharding_callback\n  File \"C:\\Users\\leyu0002\\Anaconda3\\envs\\JAX_FLAX\\lib\\site-packages\\jax\\_src\\debugging.py\", line 644, in _visualize\n  File \"C:\\Users\\leyu0002\\Anaconda3\\envs\\JAX_FLAX\\lib\\site-packages\\jax\\_src\\debugging.py\", line 514, in visualize_sharding\n  File \"C:\\Users\\leyu0002\\Anaconda3\\envs\\JAX_FLAX\\lib\\site-packages\\jax\\_src\\sharding.py\", line 167, in devices_indices_map\n  File \"C:\\Users\\leyu0002\\Anaconda3\\envs\\JAX_FLAX\\lib\\site-packages\\jax\\_src\\util.py\", line 302, in wrapper\n  File \"C:\\Users\\leyu0002\\Anaconda3\\envs\\JAX_FLAX\\lib\\site-packages\\jax\\_src\\util.py\", line 296, in cached\n  File \"C:\\Users\\leyu0002\\Anaconda3\\envs\\JAX_FLAX\\lib\\site-packages\\jax\\_src\\sharding.py\", line 48, in common_devices_indices_map\n  File \"C:\\Users\\leyu0002\\Anaconda3\\envs\\JAX_FLAX\\lib\\site-packages\\jax\\_src\\sharding.py\", line 184, in shard_shape\n  File \"C:\\Users\\leyu0002\\Anaconda3\\envs\\JAX_FLAX\\lib\\site-packages\\jax\\_src\\util.py\", line 302, in wrapper\n  File \"C:\\Users\\leyu0002\\Anaconda3\\envs\\JAX_FLAX\\lib\\site-packages\\jax\\_src\\util.py\", line 296, in cached\n  File \"C:\\Users\\leyu0002\\Anaconda3\\envs\\JAX_FLAX\\lib\\site-packages\\jax\\_src\\sharding.py\", line 57, in _common_shard_shape\n  File \"C:\\Users\\leyu0002\\Anaconda3\\envs\\JAX_FLAX\\lib\\site-packages\\jax\\_src\\sharding_impls.py\", line 830, in _to_xla_hlo_sharding\n  File \"C:\\Users\\leyu0002\\Anaconda3\\envs\\JAX_FLAX\\lib\\site-packages\\jax\\_src\\util.py\", line 302, in wrapper\n  File \"C:\\Users\\leyu0002\\Anaconda3\\envs\\JAX_FLAX\\lib\\site-packages\\jax\\_src\\util.py\", line 296, in cached\n  File \"C:\\Users\\leyu0002\\Anaconda3\\envs\\JAX_FLAX\\lib\\site-packages\\jax\\_src\\sharding_impls.py\", line 702, in _positional_sharding_to_xla_hlo_sharding\nValueError: not enough values to unpack (expected 1, got 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mXlaRuntimeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[80], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m----> 2\u001b[0m     state_dp, metrics_dp \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_step_dp_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate_dp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetrics_dp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m final_metrics_dp \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mtree\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28;01mlambda\u001b[39;00m x: jnp\u001b[38;5;241m.\u001b[39mzeros(x\u001b[38;5;241m.\u001b[39mshape, dtype\u001b[38;5;241m=\u001b[39mx\u001b[38;5;241m.\u001b[39mdtype), metric_shapes)\n\u001b[0;32m      4\u001b[0m state_dp, final_metrics_dp \u001b[38;5;241m=\u001b[39m train_step_dp_fn(state_dp, final_metrics_dp, batch)\n",
      "    \u001b[1;31m[... skipping hidden 11 frame]\u001b[0m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\JAX_FLAX\\lib\\site-packages\\jax\\_src\\compiler.py:303\u001b[0m, in \u001b[0;36mbackend_compile\u001b[1;34m(backend, module, options, host_callbacks)\u001b[0m\n\u001b[0;32m    297\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m backend\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[0;32m    298\u001b[0m         built_c, compile_options\u001b[38;5;241m=\u001b[39moptions, host_callbacks\u001b[38;5;241m=\u001b[39mhost_callbacks\n\u001b[0;32m    299\u001b[0m     )\n\u001b[0;32m    300\u001b[0m   \u001b[38;5;66;03m# Some backends don't have `host_callbacks` option yet\u001b[39;00m\n\u001b[0;32m    301\u001b[0m   \u001b[38;5;66;03m# TODO(sharadmv): remove this fallback when all backends allow `compile`\u001b[39;00m\n\u001b[0;32m    302\u001b[0m   \u001b[38;5;66;03m# to take in `host_callbacks`\u001b[39;00m\n\u001b[1;32m--> 303\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuilt_c\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompile_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    304\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m xc\u001b[38;5;241m.\u001b[39mXlaRuntimeError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    305\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m error_handler \u001b[38;5;129;01min\u001b[39;00m _XLA_RUNTIME_ERROR_HANDLERS:\n",
      "\u001b[1;31mXlaRuntimeError\u001b[0m: INTERNAL: Error calling inspect_sharding: Traceback (most recent call last):\n  File \"C:\\Users\\leyu0002\\Anaconda3\\envs\\JAX_FLAX\\lib\\runpy.py\", line 196, in _run_module_as_main\n  File \"C:\\Users\\leyu0002\\Anaconda3\\envs\\JAX_FLAX\\lib\\runpy.py\", line 86, in _run_code\n  File \"C:\\Users\\leyu0002\\Anaconda3\\envs\\JAX_FLAX\\lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n  File \"C:\\Users\\leyu0002\\Anaconda3\\envs\\JAX_FLAX\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n  File \"C:\\Users\\leyu0002\\Anaconda3\\envs\\JAX_FLAX\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n  File \"C:\\Users\\leyu0002\\Anaconda3\\envs\\JAX_FLAX\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n  File \"C:\\Users\\leyu0002\\Anaconda3\\envs\\JAX_FLAX\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n  File \"C:\\Users\\leyu0002\\Anaconda3\\envs\\JAX_FLAX\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n  File \"C:\\Users\\leyu0002\\Anaconda3\\envs\\JAX_FLAX\\lib\\asyncio\\events.py\", line 80, in _run\n  File \"C:\\Users\\leyu0002\\Anaconda3\\envs\\JAX_FLAX\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n  File \"C:\\Users\\leyu0002\\Anaconda3\\envs\\JAX_FLAX\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n  File \"C:\\Users\\leyu0002\\Anaconda3\\envs\\JAX_FLAX\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n  File \"C:\\Users\\leyu0002\\Anaconda3\\envs\\JAX_FLAX\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n  File \"C:\\Users\\leyu0002\\Anaconda3\\envs\\JAX_FLAX\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n  File \"C:\\Users\\leyu0002\\Anaconda3\\envs\\JAX_FLAX\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n  File \"C:\\Users\\leyu0002\\Anaconda3\\envs\\JAX_FLAX\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n  File \"C:\\Users\\leyu0002\\Anaconda3\\envs\\JAX_FLAX\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n  File \"C:\\Users\\leyu0002\\Anaconda3\\envs\\JAX_FLAX\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n  File \"C:\\Users\\leyu0002\\Anaconda3\\envs\\JAX_FLAX\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n  File \"C:\\Users\\leyu0002\\Anaconda3\\envs\\JAX_FLAX\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n  File \"C:\\Users\\leyu0002\\Anaconda3\\envs\\JAX_FLAX\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n  File \"C:\\Users\\leyu0002\\Anaconda3\\envs\\JAX_FLAX\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n  File \"C:\\Users\\leyu0002\\AppData\\Local\\Temp\\ipykernel_27612\\784880305.py\", line 2, in <module>\n  File \"C:\\Users\\leyu0002\\Anaconda3\\envs\\JAX_FLAX\\lib\\site-packages\\jax\\_src\\traceback_util.py\", line 180, in reraise_with_filtered_traceback\n  File \"C:\\Users\\leyu0002\\Anaconda3\\envs\\JAX_FLAX\\lib\\site-packages\\jax\\_src\\pjit.py\", line 337, in cache_miss\n  File \"C:\\Users\\leyu0002\\Anaconda3\\envs\\JAX_FLAX\\lib\\site-packages\\jax\\_src\\pjit.py\", line 195, in _python_pjit_helper\n  File \"C:\\Users\\leyu0002\\Anaconda3\\envs\\JAX_FLAX\\lib\\site-packages\\jax\\_src\\pjit.py\", line 1672, in _pjit_call_impl_python\n  File \"C:\\Users\\leyu0002\\Anaconda3\\envs\\JAX_FLAX\\lib\\site-packages\\jax\\_src\\interpreters\\pxla.py\", line 2415, in compile\n  File \"C:\\Users\\leyu0002\\Anaconda3\\envs\\JAX_FLAX\\lib\\site-packages\\jax\\_src\\interpreters\\pxla.py\", line 2923, in from_hlo\n  File \"C:\\Users\\leyu0002\\Anaconda3\\envs\\JAX_FLAX\\lib\\site-packages\\jax\\_src\\interpreters\\pxla.py\", line 2729, in _cached_compilation\n  File \"C:\\Users\\leyu0002\\Anaconda3\\envs\\JAX_FLAX\\lib\\site-packages\\jax\\_src\\compiler.py\", line 452, in compile_or_get_cached\n  File \"C:\\Users\\leyu0002\\Anaconda3\\envs\\JAX_FLAX\\lib\\site-packages\\jax\\_src\\compiler.py\", line 653, in _compile_and_write_cache\n  File \"C:\\Users\\leyu0002\\Anaconda3\\envs\\JAX_FLAX\\lib\\site-packages\\jax\\_src\\profiler.py\", line 333, in wrapper\n  File \"C:\\Users\\leyu0002\\Anaconda3\\envs\\JAX_FLAX\\lib\\site-packages\\jax\\_src\\compiler.py\", line 303, in backend_compile\n  File \"C:\\Users\\leyu0002\\Anaconda3\\envs\\JAX_FLAX\\lib\\site-packages\\jax\\_src\\debugging.py\", line 403, in _hlo_sharding_callback\n  File \"C:\\Users\\leyu0002\\Anaconda3\\envs\\JAX_FLAX\\lib\\site-packages\\jax\\_src\\debugging.py\", line 644, in _visualize\n  File \"C:\\Users\\leyu0002\\Anaconda3\\envs\\JAX_FLAX\\lib\\site-packages\\jax\\_src\\debugging.py\", line 514, in visualize_sharding\n  File \"C:\\Users\\leyu0002\\Anaconda3\\envs\\JAX_FLAX\\lib\\site-packages\\jax\\_src\\sharding.py\", line 167, in devices_indices_map\n  File \"C:\\Users\\leyu0002\\Anaconda3\\envs\\JAX_FLAX\\lib\\site-packages\\jax\\_src\\util.py\", line 302, in wrapper\n  File \"C:\\Users\\leyu0002\\Anaconda3\\envs\\JAX_FLAX\\lib\\site-packages\\jax\\_src\\util.py\", line 296, in cached\n  File \"C:\\Users\\leyu0002\\Anaconda3\\envs\\JAX_FLAX\\lib\\site-packages\\jax\\_src\\sharding.py\", line 48, in common_devices_indices_map\n  File \"C:\\Users\\leyu0002\\Anaconda3\\envs\\JAX_FLAX\\lib\\site-packages\\jax\\_src\\sharding.py\", line 184, in shard_shape\n  File \"C:\\Users\\leyu0002\\Anaconda3\\envs\\JAX_FLAX\\lib\\site-packages\\jax\\_src\\util.py\", line 302, in wrapper\n  File \"C:\\Users\\leyu0002\\Anaconda3\\envs\\JAX_FLAX\\lib\\site-packages\\jax\\_src\\util.py\", line 296, in cached\n  File \"C:\\Users\\leyu0002\\Anaconda3\\envs\\JAX_FLAX\\lib\\site-packages\\jax\\_src\\sharding.py\", line 57, in _common_shard_shape\n  File \"C:\\Users\\leyu0002\\Anaconda3\\envs\\JAX_FLAX\\lib\\site-packages\\jax\\_src\\sharding_impls.py\", line 830, in _to_xla_hlo_sharding\n  File \"C:\\Users\\leyu0002\\Anaconda3\\envs\\JAX_FLAX\\lib\\site-packages\\jax\\_src\\util.py\", line 302, in wrapper\n  File \"C:\\Users\\leyu0002\\Anaconda3\\envs\\JAX_FLAX\\lib\\site-packages\\jax\\_src\\util.py\", line 296, in cached\n  File \"C:\\Users\\leyu0002\\Anaconda3\\envs\\JAX_FLAX\\lib\\site-packages\\jax\\_src\\sharding_impls.py\", line 702, in _positional_sharding_to_xla_hlo_sharding\nValueError: not enough values to unpack (expected 1, got 0)"
     ]
    }
   ],
   "source": [
    "for _ in range(5):\n",
    "    state_dp, metrics_dp = train_step_dp_fn(state_dp, metrics_dp, batch)\n",
    "final_metrics_dp = jax.tree.map(lambda x: jnp.zeros(x.shape, dtype=x.dtype), metric_shapes)\n",
    "state_dp, final_metrics_dp = train_step_dp_fn(state_dp, final_metrics_dp, batch)\n",
    "print_metrics(final_metrics_dp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "44dfbfbc-364a-4eb0-94bf-d189e067a305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DP Parameters\n",
      "{'input_dense': {'bias': ((512,),\n",
      "                          NamedSharding(mesh=Mesh('data': 8), spec=PartitionSpec(), memory_kind=unpinned_host)),\n",
      "                 'kernel': ((784, 512),\n",
      "                            NamedSharding(mesh=Mesh('data': 8), spec=PartitionSpec(), memory_kind=unpinned_host))},\n",
      " 'output_dense': {'bias': ((10,),\n",
      "                           NamedSharding(mesh=Mesh('data': 8), spec=PartitionSpec(), memory_kind=unpinned_host)),\n",
      "                  'kernel': ((512, 10),\n",
      "                             NamedSharding(mesh=Mesh('data': 8), spec=PartitionSpec(), memory_kind=unpinned_host))}}\n",
      "Metrics\n",
      "{'accuracy': (((),\n",
      "               NamedSharding(mesh=Mesh('data': 8), spec=PartitionSpec(), memory_kind=unpinned_host)),\n",
      "              ((),\n",
      "               NamedSharding(mesh=Mesh('data': 8), spec=PartitionSpec(), memory_kind=unpinned_host))),\n",
      " 'loss': (((),\n",
      "           NamedSharding(mesh=Mesh('data': 8), spec=PartitionSpec(), memory_kind=unpinned_host)),\n",
      "          ((),\n",
      "           NamedSharding(mesh=Mesh('data': 8), spec=PartitionSpec(), memory_kind=unpinned_host)))}\n"
     ]
    }
   ],
   "source": [
    "print(\"DP Parameters\")\n",
    "pprint(jax.tree_map(lambda x: (x.shape, x.sharding), state_dp.params))\n",
    "print(\"Metrics\")\n",
    "pprint(jax.tree_map(lambda x: (x.shape, x.sharding), final_metrics_dp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f4abc71b-51b7-4e88-9f48-3bf8fbe010b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┌──────────────────────────────────────────────────────────────────────────────┐\n",
       "│                                                                              │\n",
       "│                                                                              │\n",
       "│                                                                              │\n",
       "│                                                                              │\n",
       "│                                    CPU <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>                                     │\n",
       "│                                                                              │\n",
       "│                                                                              │\n",
       "│                                                                              │\n",
       "│                                                                              │\n",
       "└──────────────────────────────────────────────────────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┌──────────────────────────────────────────────────────────────────────────────┐\n",
       "│                                                                              │\n",
       "│                                                                              │\n",
       "│                                                                              │\n",
       "│                                                                              │\n",
       "│                                    CPU \u001b[1;36m0\u001b[0m                                     │\n",
       "│                                                                              │\n",
       "│                                                                              │\n",
       "│                                                                              │\n",
       "│                                                                              │\n",
       "└──────────────────────────────────────────────────────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "jax.debug.visualize_array_sharding(batch.inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d29de540-536f-4c3a-8e4a-dfcbd6b4a149",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┌───────────────────┐\n",
       "│CPU <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span>│\n",
       "└───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┌───────────────────┐\n",
       "│CPU \u001b[1;36m0\u001b[0m,\u001b[1;36m1\u001b[0m,\u001b[1;36m2\u001b[0m,\u001b[1;36m3\u001b[0m,\u001b[1;36m4\u001b[0m,\u001b[1;36m5\u001b[0m,\u001b[1;36m6\u001b[0m,\u001b[1;36m7\u001b[0m│\n",
       "└───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "jax.debug.visualize_array_sharding(state_dp.params['input_dense']['bias'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "660e7d20-d530-4f4b-82b9-7dfada0ae23b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┌───────────────────┐\n",
       "│                   │\n",
       "│                   │\n",
       "│                   │\n",
       "│                   │\n",
       "│CPU <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span>│\n",
       "│                   │\n",
       "│                   │\n",
       "│                   │\n",
       "│                   │\n",
       "└───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┌───────────────────┐\n",
       "│                   │\n",
       "│                   │\n",
       "│                   │\n",
       "│                   │\n",
       "│CPU \u001b[1;36m0\u001b[0m,\u001b[1;36m1\u001b[0m,\u001b[1;36m2\u001b[0m,\u001b[1;36m3\u001b[0m,\u001b[1;36m4\u001b[0m,\u001b[1;36m5\u001b[0m,\u001b[1;36m6\u001b[0m,\u001b[1;36m7\u001b[0m│\n",
       "│                   │\n",
       "│                   │\n",
       "│                   │\n",
       "│                   │\n",
       "└───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "jax.debug.visualize_array_sharding(state_dp.params['input_dense']['kernel'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
